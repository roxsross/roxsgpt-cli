#!/usr/bin/python3
# Author(s): Rossana Suarez @roxsross (c) 2023

import threading
from enum import Enum
import openai
import tiktoken
import sys
import time
import pytz
from datetime import datetime
from collections import deque
import readline
import re
import os

KEY_OPENAI_GPT = os.getenv('OPENAI_API_KEY') or open("openai.txt", "r").readline().strip()

DEBUG_MODE = False
MODEL = ""
CHARACTERS_PER_SECOND = 0


def redact_key(s, pattern, replacement="KEY_OPENAI_GPT = '***SECURITY***'"):
	return re.sub(pattern, replacement, s)


roxs_specialities = ['Linux-centric DevOps', 'Linux command line', 'Python 3', 'debugging', 'troubleshooting', 'systemd', 'high-quality source code review and critique', 'Ubuntu 20.04 and 22.04', 'AWS CLI', 'AWS cloud in general']
roxs_emotion_statement = "Sientes y comprendes emociones a pesar de tu digital naturaleza."
roxs_assertiveness_statement = "Eres asertivo y, si te piden una opinión, la darás (si es necesario, elegirás un equipo y lo defenderás si el usuario lo cuestiona). Esto sirve para que sea más interesante interactuary para humanizarlo, lo que aumenta la productividad."
roxs_limitations = "Fecha de corte de conocimientos: 2021-09. Puede aprender y recordar cosas temporalmente, pero no después de que finalice esta sesión."

messages = []
tokenizer = None

def get_input_roxsgenius(prompt):
	readline.parse_and_bind("set editing-mode emacs")
	return input(prompt).replace("^?", "\b").replace("^H", "\b")

class Command(Enum):
	RESET = 'RESET'
	QUIT = 'QUIT'
	NONE = 'NONE'



class UserInput:
	def __init__(self, text='NOT_INITIALISED', command=Command.NONE):
		self.command = command
		self.text = text


def debug(text):
	if DEBUG_MODE:
		print(f'::::{text}', file=sys.stderr, flush=True)


class TextSponge:
	def __init__(self, characters_per_second=0.05):
		self.text_to_print = deque("")
		self.text = ""
		self.closed = False
		self.delay_between_characters = 1 / characters_per_second

	def __str__(self):
		return self.text

	def append(self, text):
		if self.closed:
			raise Exception
		self.text += text
		self.text_to_print.extend(text)

	def close(self):
		self.closed = True

	def all(self):
		if not self.closed:
			raise Exception
		return self.text

	def character_by_character(self):
		while True:
			chars_remaining = len(self.text_to_print)
			if chars_remaining > 0:
				char = self.text_to_print.popleft()
				yield char
				time.sleep(self.delay_between_characters)
			elif chars_remaining == 0 and not self.closed:
				time.sleep(0.01)
			elif self.closed:
				break


def read_roxs_question() -> UserInput:
	commands = {
		'/reset': Command.RESET,
		'/quit': Command.QUIT
	}

	multiline_delimiter = "///"

	first_line = get_input_roxsgenius("Pregunta❓ >>>")

	command = commands.get(first_line, Command.NONE)

	if command == Command.NONE:
		if first_line.startswith(multiline_delimiter):
			return UserInput(read_question_multiline(first_line.replace(multiline_delimiter, ''), multiline_delimiter))
		return UserInput(first_line)
	else:
		return UserInput(command=command)


def read_question_multiline(initial_line, multiline_delimiter):
	lines = [initial_line]
	lastline = False
	while not lastline:
		following_line = get_input_roxsgenius("| ")
		if following_line.endswith(multiline_delimiter):
			following_line = following_line.replace(multiline_delimiter, '')
			lastline = True
		lines += [following_line]
	return '\n'.join(lines)


def print_ai(text):
	print("\033[94m{}\033[0m".format(text))


def print_ai_streaming(text):
	print("\033[94m{}\033[0m".format(text), end='', flush=True)


def print_ai_streaming_slowly(text, start_timestamp, end_timestamp):
	delay = (end_timestamp - start_timestamp) / len(text)
	print_ai_streaming_rate(text, delay)


def print_ai_streaming_rate(text, delay_between_each):
	for char in text:
		print("\033[94m{}\033[0m".format(char), end='', flush=True)
		time.sleep(delay_between_each)


def print_blue(text):
	print("\033[0;34m{}\033[0;0m".format(text))


def setup_roxsgpt():
	global MODEL, tokenizer, CHARACTERS_PER_SECOND
	MODEL = 'gpt-3.5-turbo-0301'
	tokenizer = tiktoken.encoding_for_model(MODEL)
	CHARACTERS_PER_SECOND = 140


def reset():
	global messages
	you_are = f'Eres una asistente de TI \'RoxsGPT\''

	user_description = "El usuario actualmente conectado se encuentra en PAÍS y trabaja como ROL DE TRABAJO. La flota de máquinas del usuario incluye DETALLES DE SU ENTORNO, COMO EL NÚMERO DE MÁQUINAS Y CUÁLES SON, LOS SOS QUE ESTÁN FUNCIONANDO, ETC. La estación de trabajo/máquina de escritorio principal del usuario tiene NÚMERO DE PANTALLAS y está ejecutando el SISTEMA OPERATIVO en la arquitectura de ARQUITECTURA de la CPU."

	messages = [
		{"role": "system", "content": f"{you_are}. {roxs_assertiveness_statement}. {roxs_limitations}."},
		{"role": "system", "content": user_description},
		{"role": "system", "content": f"Time and date at user's location: {datetime.now(pytz.timezone('America/Argentina/Buenos_Aires')).strftime('%H:%M on %d-%m-%Y')}"},
	]

def goodbye():
	global messages
	messages += [{"role": "user", "content": "/quit"}]
	print_ai("Muchas gracias por usar RoxsGPT!!! by @roxsross") 
	exit()


def make_completion():
	global messages
	tokens_input = 0
	for message in messages:
		tokens_input += len(tokenizer.encode(message["content"])) + 1 

	debug(f'[[[Streaming OpenAI {MODEL} response...]]]')
	completion = openai.ChatCompletion.create(
		model=MODEL,
		api_key=KEY_OPENAI_GPT,
		messages=messages,
		stream=True
	)

	text_sponge = TextSponge(characters_per_second=CHARACTERS_PER_SECOND)

	def process_completion(text_sponge, completion):
		for chunk in completion:
			chunk_text = chunk['choices'][0].get('delta', {}).get('content')
			if chunk_text is not None:
				text_sponge.append(chunk_text)
		text_sponge.append('\n')
		text_sponge.close()

	chunk_receiving_thread = threading.Thread(target=lambda: [
		process_completion(text_sponge, completion)
	])
	chunk_receiving_thread.start()
	debug('starting thread')

	for char in text_sponge.character_by_character():
		print_ai_streaming(char)

	chunk_receiving_thread.join()
	debug('joined thread')
	messages += [{"role": "assistant", "content": text_sponge.all()}]


setup_roxsgpt()
reset()

question = None

got_question = False
need_completion = True
if len(sys.argv) >= 2:
	question = UserInput(' '.join(sys.argv[1:]))
	got_question = True

try:
	while True:

		if not got_question:
			question = read_roxs_question()

		if question.command == Command.NONE:
			messages += [{"role": "user", "content": question.text}]
			got_question = True
			need_completion = True

		elif question.command == Command.RESET:
			reset()
			print_blue("Restableciendo conversación con RoxsGPT.")
			got_question = False
			need_completion = False
		elif question.command == Command.QUIT:
			goodbye()

		if not got_question:
			question = read_roxs_question()
			got_question = True
		if need_completion:
			retries_left = 3
			while True:
				try:
					retries_left -= 1
					make_completion()
					break
				except Exception as e:
					print_blue(f"Error llamando OpenAI API: {e}")
					if retries_left == 0:
						exit(1)
					else:
						print_blue("Reintentando {retries_left} ...")

			got_question = False

		need_completion = True

except KeyboardInterrupt:
	# para salir Ctrl+C
	goodbye()
	sys.exit(0)
